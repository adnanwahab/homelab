{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844a6d19-acd9-484b-b33c-af6f175a2882",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://files.cooperative-robotics.com/intermediate_representation/robotics_knowledge_book_of_future/driving/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path = '/home/adnan/derp/intermediate_representation/robotics_knowledge_book_of_future/driving'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f122cb8-f611-4384-ae59-028d070cf1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ab6f919-28df-405c-aeab-1918b66107d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m125 packages\u001b[0m \u001b[2min 925ms\u001b[0m\u001b[0m                                       \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m76 packages\u001b[0m \u001b[2min 1.57s\u001b[0m\u001b[0m                                            \n",
      "\u001b[2mUninstalled \u001b[1m5 packages\u001b[0m \u001b[2min 33ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m80 packages\u001b[0m \u001b[2min 47ms\u001b[0m\u001b[0mentation-langchain==0.36.1     \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1margparse\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbackoff\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mboto3\u001b[0m\u001b[2m==1.36.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbotocore\u001b[0m\u001b[2m==1.36.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbrowser-use\u001b[0m\u001b[2m==0.1.25\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcachetools\u001b[0m\u001b[2m==5.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcourlan\u001b[0m\u001b[2m==1.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdateparser\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdeprecated\u001b[0m\u001b[2m==1.2.15\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfiletype\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfireworks-ai\u001b[0m\u001b[2m==0.15.11\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-ai-generativelanguage\u001b[0m\u001b[2m==0.6.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-api-core\u001b[0m\u001b[2m==2.24.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-api-python-client\u001b[0m\u001b[2m==2.159.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-auth\u001b[0m\u001b[2m==2.37.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-auth-httplib2\u001b[0m\u001b[2m==0.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-generativeai\u001b[0m\u001b[2m==0.8.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogleapis-common-protos\u001b[0m\u001b[2m==1.66.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgrpcio\u001b[0m\u001b[2m==1.69.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgrpcio-status\u001b[0m\u001b[2m==1.69.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhtml2text\u001b[0m\u001b[2m==2024.2.26\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhtmldate\u001b[0m\u001b[2m==1.9.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttplib2\u001b[0m\u001b[2m==0.22.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.27.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx-sse\u001b[0m\u001b[2m==0.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx-ws\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjmespath\u001b[0m\u001b[2m==1.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjustext\u001b[0m\u001b[2m==3.0.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mlangchain\u001b[0m\u001b[2m==0.2.17\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain\u001b[0m\u001b[2m==0.3.14\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mlangchain-anthropic\u001b[0m\u001b[2m==0.1.23\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-anthropic\u001b[0m\u001b[2m==0.3.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-aws\u001b[0m\u001b[2m==0.2.11\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mlangchain-core\u001b[0m\u001b[2m==0.2.43\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-core\u001b[0m\u001b[2m==0.3.30\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-fireworks\u001b[0m\u001b[2m==0.2.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-google-genai\u001b[0m\u001b[2m==2.0.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-ollama\u001b[0m\u001b[2m==0.2.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-openai\u001b[0m\u001b[2m==0.3.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mlangchain-text-splitters\u001b[0m\u001b[2m==0.2.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-text-splitters\u001b[0m\u001b[2m==0.3.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlmnr\u001b[0m\u001b[2m==0.4.53\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlxml\u001b[0m\u001b[2m==5.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlxml-html-clean\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmaincontentextractor\u001b[0m\u001b[2m==0.0.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmonotonic\u001b[0m\u001b[2m==1.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mollama\u001b[0m\u001b[2m==0.4.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.59.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-api\u001b[0m\u001b[2m==1.29.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-exporter-otlp-proto-common\u001b[0m\u001b[2m==1.29.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-exporter-otlp-proto-grpc\u001b[0m\u001b[2m==1.29.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-exporter-otlp-proto-http\u001b[0m\u001b[2m==1.29.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-instrumentation\u001b[0m\u001b[2m==0.50b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-instrumentation-langchain\u001b[0m\u001b[2m==0.36.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-instrumentation-requests\u001b[0m\u001b[2m==0.50b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-instrumentation-sqlalchemy\u001b[0m\u001b[2m==0.50b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-instrumentation-threading\u001b[0m\u001b[2m==0.50b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-instrumentation-urllib3\u001b[0m\u001b[2m==0.50b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-proto\u001b[0m\u001b[2m==1.29.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-sdk\u001b[0m\u001b[2m==1.29.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-semantic-conventions\u001b[0m\u001b[2m==0.50b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-semantic-conventions-ai\u001b[0m\u001b[2m==0.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-util-http\u001b[0m\u001b[2m==0.50b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mplaywright\u001b[0m\u001b[2m==1.49.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mposthog\u001b[0m\u001b[2m==3.8.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mproto-plus\u001b[0m\u001b[2m==1.25.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==5.29.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyasn1\u001b[0m\u001b[2m==0.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyasn1-modules\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyee\u001b[0m\u001b[2m==12.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyparsing\u001b[0m\u001b[2m==3.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2024.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2024.11.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrsa\u001b[0m\u001b[2m==4.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1ms3transfer\u001b[0m\u001b[2m==0.11.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtiktoken\u001b[0m\u001b[2m==0.8.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtld\u001b[0m\u001b[2m==0.13\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtrafilatura\u001b[0m\u001b[2m==2.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtzlocal\u001b[0m\u001b[2m==5.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1muritemplate\u001b[0m\u001b[2m==4.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwrapt\u001b[0m\u001b[2m==1.17.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwsproto\u001b[0m\u001b[2m==1.2.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install browser-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f339eec7-ae00-4cc9-be88-56d8ba139aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m106 packages\u001b[0m \u001b[2min 752ms\u001b[0m\u001b[0m                                       \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m20 packages\u001b[0m \u001b[2min 1.06s\u001b[0m\u001b[0m                                            \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m24 packages\u001b[0m \u001b[2min 230ms\u001b[0m\u001b[0m                              \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1masgiref\u001b[0m\u001b[2m==3.8.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbcrypt\u001b[0m\u001b[2m==4.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbuild\u001b[0m\u001b[2m==1.2.2.post1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mchroma-hnswlib\u001b[0m\u001b[2m==0.7.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mchromadb\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcoloredlogs\u001b[0m\u001b[2m==15.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdurationpy\u001b[0m\u001b[2m==0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.16.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mflatbuffers\u001b[0m\u001b[2m==24.12.23\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.27.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhumanfriendly\u001b[0m\u001b[2m==10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mimportlib-resources\u001b[0m\u001b[2m==6.5.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkubernetes\u001b[0m\u001b[2m==31.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmmh3\u001b[0m\u001b[2m==5.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1moauthlib\u001b[0m\u001b[2m==3.2.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1monnxruntime\u001b[0m\u001b[2m==1.20.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-instrumentation-asgi\u001b[0m\u001b[2m==0.50b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-instrumentation-fastapi\u001b[0m\u001b[2m==0.50b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpypika\u001b[0m\u001b[2m==0.48.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyproject-hooks\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests-oauthlib\u001b[0m\u001b[2m==2.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.13.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.21.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain chromadb tiktoken  # Install dependencies in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48b7fae1-ac1b-4f58-9f87-11cc6f3a79dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error loading file /home/adnan/derp/intermediate_representation/robotics_knowledge_book_of_future/driving/vetur.config.js\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n\n  Searched in:\n    - '/home/adnan/nltk_data'\n    - '/home/adnan/homelab/.venv/nltk_data'\n    - '/home/adnan/homelab/.venv/share/nltk_data'\n    - '/home/adnan/homelab/.venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 98\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vectorstore\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# 6) Putting it all together: Index the codebase\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m documents \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_split_codebase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCODEBASE_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m ollama_embeddings \u001b[38;5;241m=\u001b[39m OllamaEmbeddingFunction()\n\u001b[1;32m    100\u001b[0m code_vector_store \u001b[38;5;241m=\u001b[39m create_vector_store(documents, ollama_embeddings, store_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdriving_code_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 68\u001b[0m, in \u001b[0;36mload_and_split_codebase\u001b[0;34m(path, suffixes)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03mRecursively load documents from the given path.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03mAdjust `suffixes` to match the file types you care about (C++, Python, etc.)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m loader \u001b[38;5;241m=\u001b[39m DirectoryLoader(path, glob\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**/*\u001b[39m\u001b[38;5;124m\"\u001b[39m, recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 68\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Filter by suffix if desired (DirectoryLoader might pick up everything)\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# docs = [d for d in docs if any(d.metadata[\"source\"].endswith(s) for s in suffixes)]\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Split large files into smaller chunks to avoid token/embedding limits\u001b[39;00m\n\u001b[1;32m     74\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(\n\u001b[1;32m     75\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,  \u001b[38;5;66;03m# You can adjust chunk size\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     77\u001b[0m )\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/langchain_community/document_loaders/directory.py:117\u001b[0m, in \u001b[0;36mDirectoryLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load documents.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/langchain_community/document_loaders/directory.py:195\u001b[0m, in \u001b[0;36mDirectoryLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[0;32m--> 195\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_load_file(i, p, pbar)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pbar:\n\u001b[1;32m    198\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/langchain_community/document_loaders/directory.py:233\u001b[0m, in \u001b[0;36mDirectoryLoader._lazy_load_file\u001b[0;34m(self, item, path, pbar)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(item)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 233\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pbar:\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/langchain_community/document_loaders/directory.py:223\u001b[0m, in \u001b[0;36mDirectoryLoader._lazy_load_file\u001b[0;34m(self, item, path, pbar)\u001b[0m\n\u001b[1;32m    221\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_cls(\u001b[38;5;28mstr\u001b[39m(item), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_kwargs)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubdoc\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/langchain_community/document_loaders/unstructured.py:107\u001b[0m, in \u001b[0;36mUnstructuredBaseLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlazy_load\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Document]:\n\u001b[1;32m    106\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_elements(elements)\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melements\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/langchain_community/document_loaders/unstructured.py:228\u001b[0m, in \u001b[0;36mUnstructuredFileLoader._get_elements\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path, Path):\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path)\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munstructured_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/unstructured/partition/auto.py:288\u001b[0m, in \u001b[0;36mpartition\u001b[0;34m(filename, file, encoding, content_type, url, headers, ssl_verify, request_timeout, strategy, skip_infer_table_types, ocr_languages, languages, detect_language_per_element, pdf_infer_table_structure, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, data_source_metadata, metadata_filename, hi_res_model_name, model_name, starting_page_number, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m partitioning_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrategy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m strategy\n\u001b[1;32m    287\u001b[0m partition \u001b[38;5;241m=\u001b[39m partitioner_loader\u001b[38;5;241m.\u001b[39mget(file_type)\n\u001b[0;32m--> 288\u001b[0m elements \u001b[38;5;241m=\u001b[39m \u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpartitioning_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m augment_metadata(elements)\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/unstructured/partition/common/metadata.py:162\u001b[0m, in \u001b[0;36mapply_metadata.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Element]:\n\u001b[0;32m--> 162\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     call_args \u001b[38;5;241m=\u001b[39m get_call_args_applying_defaults(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# ------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# unique-ify elements\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# ------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;66;03m# instance).\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# ------------------------------------------------------------------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/unstructured/chunking/dispatch.py:74\u001b[0m, in \u001b[0;36madd_chunking_strategy.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The decorated function is replaced with this one.\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# -- call the partitioning function to get the elements --\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m elements \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# -- look for a chunking-strategy argument --\u001b[39;00m\n\u001b[1;32m     77\u001b[0m call_args \u001b[38;5;241m=\u001b[39m get_call_args_applying_defaults(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/unstructured/partition/text.py:104\u001b[0m, in \u001b[0;36mpartition_text\u001b[0;34m(filename, file, encoding, text, paragraph_grouper, detection_origin, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m ctext \u001b[38;5;241m=\u001b[39m ctext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ctext \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_empty_bullet(ctext):\n\u001b[0;32m--> 104\u001b[0m     element \u001b[38;5;241m=\u001b[39m \u001b[43melement_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     element\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(metadata)\n\u001b[1;32m    106\u001b[0m     elements\u001b[38;5;241m.\u001b[39mappend(element)\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/unstructured/partition/text.py:149\u001b[0m, in \u001b[0;36melement_from_text\u001b[0;34m(text, coordinates, coordinate_system)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_possible_numbered_list(text):\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListItem(\n\u001b[1;32m    145\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m    146\u001b[0m         coordinates\u001b[38;5;241m=\u001b[39mcoordinates,\n\u001b[1;32m    147\u001b[0m         coordinate_system\u001b[38;5;241m=\u001b[39mcoordinate_system,\n\u001b[1;32m    148\u001b[0m     )\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mis_possible_narrative_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NarrativeText(\n\u001b[1;32m    151\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m    152\u001b[0m         coordinates\u001b[38;5;241m=\u001b[39mcoordinates,\n\u001b[1;32m    153\u001b[0m         coordinate_system\u001b[38;5;241m=\u001b[39mcoordinate_system,\n\u001b[1;32m    154\u001b[0m     )\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_possible_title(text):\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/unstructured/partition/text_type.py:84\u001b[0m, in \u001b[0;36mis_possible_narrative_text\u001b[0;34m(text, cap_threshold, non_alpha_threshold, languages, language_checks)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m under_non_alpha_ratio(text, threshold\u001b[38;5;241m=\u001b[39mnon_alpha_threshold):\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m languages \u001b[38;5;129;01mand\u001b[39;00m (sentence_count(text, \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontains_verb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     85\u001b[0m     trace_logger\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot narrative. Text does not contain a verb:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore # noqa: E501\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/unstructured/partition/text_type.py:186\u001b[0m, in \u001b[0;36mcontains_verb\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text\u001b[38;5;241m.\u001b[39misupper():\n\u001b[1;32m    184\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m--> 186\u001b[0m pos_tags \u001b[38;5;241m=\u001b[39m \u001b[43mpos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28many\u001b[39m(tag \u001b[38;5;129;01min\u001b[39;00m POS_VERB_TAGS \u001b[38;5;28;01mfor\u001b[39;00m _, tag \u001b[38;5;129;01min\u001b[39;00m pos_tags)\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/unstructured/nlp/tokenize.py:55\u001b[0m, in \u001b[0;36mpos_tag\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences:\n\u001b[1;32m     54\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m _word_tokenize(sentence)\n\u001b[0;32m---> 55\u001b[0m     parts_of_speech\u001b[38;5;241m.\u001b[39mextend(\u001b[43m_pos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parts_of_speech\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/nltk/tag/__init__.py:168\u001b[0m, in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpos_tag\u001b[39m(tokens, tagset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m    Use NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m    tag the given list of tokens.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m    :rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m \u001b[43m_get_tagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pos_tag(tokens, tagset, tagger, lang)\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/nltk/tag/__init__.py:110\u001b[0m, in \u001b[0;36m_get_tagger\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m    108\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m PerceptronTagger(lang\u001b[38;5;241m=\u001b[39mlang)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m \u001b[43mPerceptronTagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tagger\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/nltk/tag/perceptron.py:183\u001b[0m, in \u001b[0;36mPerceptronTagger.__init__\u001b[0;34m(self, load, lang)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load:\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/nltk/tag/perceptron.py:273\u001b[0m, in \u001b[0;36mPerceptronTagger.load_from_json\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_from_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# Automatically find path to the tagger if location is not specified.\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtaggers/averaged_perceptron_tagger_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(loc \u001b[38;5;241m+\u001b[39m TAGGER_JSONS[lang][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(fin)\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/nltk/data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n\n  Searched in:\n    - '/home/adnan/nltk_data'\n    - '/home/adnan/homelab/.venv/nltk_data'\n    - '/home/adnan/homelab/.venv/share/nltk_data'\n    - '/home/adnan/homelab/.venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "from typing import List\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# 1) Define your project path\n",
    "CODEBASE_PATH = '/home/adnan/derp/intermediate_representation/robotics_knowledge_book_of_future/driving'\n",
    "\n",
    "# 2) Helper function to call `ollama embed` and retrieve the embedding\n",
    "def get_ollama_embedding(text: str, model: str = \"llama2\"):\n",
    "    \"\"\"\n",
    "    Calls `ollama embed` via subprocess and returns the embedding as a list of floats.\n",
    "    Args:\n",
    "        text: The text to embed\n",
    "        model: The Ollama model name (default is llama2, or your local model alias)\n",
    "    \"\"\"\n",
    "    # Note: You might need to adjust command parameters based on your model or GPU/CPU usage\n",
    "    cmd = [\"ollama\", \"embed\", \"--model\", model, text]\n",
    "    \n",
    "    # Run Ollama embedding command\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"Error embedding text:\", result.stderr)\n",
    "        return None\n",
    "    \n",
    "    # Parse JSON output to extract embedding array\n",
    "    try:\n",
    "        # Ollama's embed output is a JSON object with \"embedding\": [...]\n",
    "        output_json = json.loads(result.stdout)\n",
    "        embedding = output_json.get(\"embedding\", [])\n",
    "        return embedding\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Failed to parse Ollama output as JSON.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# 3) Build a custom embedding function to integrate with LangChain\n",
    "#    so it can handle chunks and store them in a vector database.\n",
    "class OllamaEmbeddingFunction:\n",
    "    \"\"\"A LangChain-compatible embedding function that calls `ollama embed`.\"\"\"\n",
    "    \n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Embeds multiple documents (chunks).\"\"\"\n",
    "        embeddings = []\n",
    "        for t in texts:\n",
    "            emb = get_ollama_embedding(t)\n",
    "            if emb is None:\n",
    "                emb = []\n",
    "            embeddings.append(emb)\n",
    "        return embeddings\n",
    "    \n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"Embeds a single query string.\"\"\"\n",
    "        emb = get_ollama_embedding(text)\n",
    "        return emb if emb else []\n",
    "\n",
    "\n",
    "# 4) Load files from the directory, split into chunks\n",
    "def load_and_split_codebase(path: str, suffixes=(\".cpp\", \".h\", \".py\", \".java\", \".md\", \".txt\")):\n",
    "    \"\"\"\n",
    "    Recursively load documents from the given path.\n",
    "    Adjust `suffixes` to match the file types you care about (C++, Python, etc.)\n",
    "    \"\"\"\n",
    "    loader = DirectoryLoader(path, glob=\"**/*\", recursive=True)\n",
    "    docs = loader.load()\n",
    "    \n",
    "    # Filter by suffix if desired (DirectoryLoader might pick up everything)\n",
    "    # docs = [d for d in docs if any(d.metadata[\"source\"].endswith(s) for s in suffixes)]\n",
    "    \n",
    "    # Split large files into smaller chunks to avoid token/embedding limits\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,  # You can adjust chunk size\n",
    "        chunk_overlap=100\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(docs)\n",
    "    return split_docs\n",
    "\n",
    "\n",
    "# 5) Create or load a vector store with Ollama embeddings\n",
    "def create_vector_store(documents, embedding_function, store_path=\"code_index\"):\n",
    "    \"\"\"\n",
    "    Creates a Chroma vector store of the given documents using the Ollama embedding function.\n",
    "    Store path is where the DB will live on disk.\n",
    "    \"\"\"\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents,\n",
    "        embedding_function,\n",
    "        persist_directory=store_path\n",
    "    )\n",
    "    vectorstore.persist()  # Persist to disk for reuse\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "# 6) Putting it all together: Index the codebase\n",
    "documents = load_and_split_codebase(CODEBASE_PATH)\n",
    "ollama_embeddings = OllamaEmbeddingFunction()\n",
    "code_vector_store = create_vector_store(documents, ollama_embeddings, store_path=\"driving_code_index\")\n",
    "\n",
    "print(f\"Indexed {len(documents)} chunks from the codebase.\")\n",
    "print(\"Vector store built at 'driving_code_index' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d0f26c-9c33-46d6-b326-e20a6b72f3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0573d8ac-329e-4a56-b42c-5e7a95de2c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/adnan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f1026c3-eaf0-4fc9-9e52-4c25483b626a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m56 packages\u001b[0m \u001b[2min 447ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m18 packages\u001b[0m \u001b[2min 662ms\u001b[0m\u001b[0m                                            \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m19 packages\u001b[0m \u001b[2min 10ms\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiofiles\u001b[0m\u001b[2m==24.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mchardet\u001b[0m\u001b[2m==5.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcryptography\u001b[0m\u001b[2m==44.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1memoji\u001b[0m\u001b[2m==2.14.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1meval-type-backport\u001b[0m\u001b[2m==0.2.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhtml5lib\u001b[0m\u001b[2m==1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonpath-python\u001b[0m\u001b[2m==1.0.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangdetect\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mndjson\u001b[0m\u001b[2m==0.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnltk\u001b[0m\u001b[2m==3.9.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1molefile\u001b[0m\u001b[2m==0.47\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpypdf\u001b[0m\u001b[2m==5.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-iso639\u001b[0m\u001b[2m==2024.10.22\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-magic\u001b[0m\u001b[2m==0.4.27\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-oxmsg\u001b[0m\u001b[2m==0.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrapidfuzz\u001b[0m\u001b[2m==3.11.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1munstructured\u001b[0m\u001b[2m==0.16.14\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1munstructured-client\u001b[0m\u001b[2m==0.29.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f6471c-6144-43cf-9d59-dc6bb57dc277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2f2525-a931-4a30-9f02-d130dc309f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380406e1-cb78-43c0-8844-2458168cbe77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b47bcfab-25e2-4545-965c-e77a55b54c67",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ollama_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[1;32m      2\u001b[0m code_vector_store \u001b[38;5;241m=\u001b[39m Chroma(\n\u001b[0;32m----> 3\u001b[0m     embedding_function\u001b[38;5;241m=\u001b[39m\u001b[43mollama_embeddings\u001b[49m,\n\u001b[1;32m      4\u001b[0m     persist_directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdriving_code_index\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ollama_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "code_vector_store = Chroma(\n",
    "    embedding_function=ollama_embeddings,\n",
    "    persist_directory=\"driving_code_index\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
