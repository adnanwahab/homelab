{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "810be422-c803-401d-b50d-66b10215a1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Response: {'choices': [{'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}, 'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': \"Hello! ðŸ‘‹ It looks like you're working with Python's `requests` library. How can I assist you today? Do you need help with making HTTP requests, handling responses, or debugging your code? Let me know! ðŸš€\", 'refusal': None, 'role': 'assistant'}}], 'created': 1738072636, 'id': 'chatcmpl-AugNYFCxQN9ZlC0IRvCXgVtHZXd10', 'model': 'gpt-4o-2024-11-20', 'object': 'chat.completion', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'system_fingerprint': 'fp_f3927aa00d', 'usage': {'completion_tokens': 47, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 22, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 69}}\n"
=======
      "\u001b[2K\u001b[2mResolved \u001b[1m19 packages\u001b[0m \u001b[2min 230ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m8 packages\u001b[0m \u001b[2min 71ms\u001b[0m\u001b[0m                                              \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m10 packages\u001b[0m \u001b[2min 16ms\u001b[0m\u001b[0m0                              \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mazure-ai-inference\u001b[0m\u001b[2m==1.0.0b7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mazure-ai-projects\u001b[0m\u001b[2m==1.0.0b5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mazure-core\u001b[0m\u001b[2m==1.32.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mazure-identity\u001b[0m\u001b[2m==1.19.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcryptography\u001b[0m\u001b[2m==44.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1misodate\u001b[0m\u001b[2m==0.7.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmsal\u001b[0m\u001b[2m==1.31.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmsal-extensions\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mportalocker\u001b[0m\u001b[2m==2.10.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyjwt\u001b[0m\u001b[2m==2.10.1\u001b[0m\n"
>>>>>>> d306c12 (simplify)
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "import os\n",
    "import requests\n",
    "\n",
    "endpoint = \"https://ai-dynabotdev4539ai796342985711.openai.azure.com/\"\n",
    "deployment_name = \"gpt-4o\"\n",
    "api_version = \"2023-07-01-preview\"\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\") or \"7NlEk01KPV1og3Pt0hFmtchJ0kQhlw11eTfmIkR6Clhwi84aWVrsJQQJ99BAACHYHv6XJ3w3AAAAACOGbMBI\"\n",
    "\n",
    "url = f\"{endpoint}/openai/deployments/{deployment_name}/chat/completions?api-version={api_version}\"\n",
    "#url = 'https://ai-dynabotdev4539ai796342985711.openai.azure.com/'\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": api_key\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",   \"content\": \"Hello from Python requests!\"}\n",
    "    ],\n",
    "    \"max_tokens\": 100\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "if response.status_code == 200:\n",
    "    print(\"Response:\", response.json())\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)\n"
   ]
=======
    "! uv pip install azure-ai-projects azure-ai-inference azure-identity \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076a6c83-533e-4e80-ad58-413df3c5a653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c94e2230-c249-4e9b-b928-c672cfecc958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install  azure-ai-inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6390186b-bd79-4833-aa04-e93020abf05f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceNotFoundError",
     "evalue": "(404) Resource not found\nCode: 404\nMessage: Resource not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceNotFoundError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 34\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# [END chat_completions]\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[43msample_chat_completions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 22\u001b[0m, in \u001b[0;36msample_chat_completions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcredentials\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureKeyCredential\n\u001b[1;32m     20\u001b[0m client \u001b[38;5;241m=\u001b[39m ChatCompletionsClient(endpoint\u001b[38;5;241m=\u001b[39mendpoint, credential\u001b[38;5;241m=\u001b[39mAzureKeyCredential(key))\n\u001b[0;32m---> 22\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mSystemMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful assistant.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mUserMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHow many feet are in a mile?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/azure/ai/inference/_patch.py:728\u001b[0m, in \u001b[0;36mChatCompletionsClient.complete\u001b[0;34m(self, body, messages, stream, frequency_penalty, presence_penalty, temperature, top_p, max_tokens, response_format, stop, tools, tool_choice, seed, model, model_extras, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _stream:\n\u001b[1;32m    727\u001b[0m         response\u001b[38;5;241m.\u001b[39mread()  \u001b[38;5;66;03m# Load the body in memory and close the socket\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m     \u001b[43mmap_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _stream:\n",
      "File \u001b[0;32m~/homelab/.venv/lib/python3.12/site-packages/azure/core/exceptions.py:163\u001b[0m, in \u001b[0;36mmap_error\u001b[0;34m(status_code, response, error_map)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    162\u001b[0m error \u001b[38;5;241m=\u001b[39m error_type(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mResourceNotFoundError\u001b[0m: (404) Resource not found\nCode: 404\nMessage: Resource not found"
     ]
    }
   ],
   "source": [
    "#endpoint = \n",
    "azure_api_key = '7NlEk01KPV1og3Pt0hFmtchJ0kQhlw11eTfmIkR6Clhwi84aWVrsJQQJ99BAACHYHv6XJ3w3AAAAACOGbMBI'\n",
    "\n",
    "def sample_chat_completions():\n",
    "    import os\n",
    "\n",
    "    try:\n",
    "        endpoint = 'https://ai-dynabotdev4539ai796342985711.openai.azure.com/'#os.environ[\"AZURE_AI_CHAT_ENDPOINT\"]\n",
    "        key = azure_api_key#os.environ[\"AZURE_AI_CHAT_KEY\"]\n",
    "    except KeyError:\n",
    "        print(\"Missing environment variable 'AZURE_AI_CHAT_ENDPOINT' or 'AZURE_AI_CHAT_KEY'\")\n",
    "        print(\"Set them before running this sample.\")\n",
    "        exit()\n",
    "\n",
    "    # [START chat_completions]\n",
    "    from azure.ai.inference import ChatCompletionsClient\n",
    "    from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "    from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "    client = ChatCompletionsClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n",
    "\n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            SystemMessage(\"You are a helpful assistant.\"),\n",
    "            UserMessage(\"How many feet are in a mile?\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].message.content)\n",
    "    # [END chat_completions]\n",
    "\n",
    "\n",
    "\n",
    "sample_chat_completions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc5616b-e958-4705-859a-b7c2a9832cb3",
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> d306c12 (simplify)
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
